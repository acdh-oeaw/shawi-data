{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34c743a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ELAN to TEI conversion \n",
    "\n",
    "**Author:** Daniel Schopper    \n",
    "**Description:** This notebook automates the ELAN to TEI conversion in the SHAWI Project. When finished, it should be ported to a non-interactive script which is triggered by a github action.    \n",
    "**Last Change:** 2022-03-23     \n",
    "**History:**    \n",
    "* 2022-03-10: Initital set up\n",
    "* 2022-03-11: added XSLT transformation via saxonpy\n",
    "* 2022-03-12: added ELAN to TEI conversion\n",
    "* 2022-03-23: integrated merge metadata XSL\n",
    "\n",
    "## TODOS and Open Questions\n",
    "\n",
    "* merge documents, making sure to not overwrite manual changes\n",
    "* replace TEI documents with x-includes\n",
    "* tokenize\n",
    "* validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c93b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sharepy\n",
    "import os\n",
    "import requests\n",
    "import pathlib\n",
    "#import filetype â€“ not used\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlsplit\n",
    "from saxonpy import PySaxonProcessor, PyXdmValue\n",
    "from zipfile import ZipFile\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "# from inspect import getmembers, signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd189fd",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65d673ca-740f-4d11-93b7-a9036750f5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saxon/C 1.2.1 running with Saxon-HE 9.9.1.5C from Saxonica\n",
      "/home/simar/shawi-data/080_scripts_generic\n",
      "** setting up directories **\n",
      "skipped existing directory 'data'\n",
      "skipped existing directory 'lib'\n"
     ]
    }
   ],
   "source": [
    "# the URL of the Sharepoint installation \n",
    "sp_baseURL = \"oeawacat.sharepoint.com\"\n",
    "\n",
    "# the sharepoint username + password are taken from the environment\n",
    "sp_username = os.environ['SP_USERNAME']\n",
    "sp_pwd = pwd = os.environ['SP_PWD']\n",
    "\n",
    "# the name of the Sharepoint Site\n",
    "sp_siteName = \"ACDH-CH_p_ShawiTypeArabicDialects_Shawi\"\n",
    "\n",
    "# the path to the Excel file\n",
    "sp_pathToRecordingsXLSX = \"Shared Documents/General/Shawi_Recordings.xlsx\"\n",
    "\n",
    "\n",
    "# the name of the local directory where downloaded data will be stored\n",
    "dataDir = \"data\"\n",
    "\n",
    "# the name of the local directory where downloaded libraries and other auxiliary code will be stored\n",
    "libDir = \"lib\"\n",
    "\n",
    "# the root of the git repository\n",
    "shawidataHomeDir = \"../..\"\n",
    "\n",
    "# path to project-specific stylesheets\n",
    "pathToShawiStylesheetsDir = shawidataHomeDir+\"/082_scripts_xsl\"\n",
    "\n",
    "# the path to the ELAN transcription files\n",
    "pathToELANDir = shawidataHomeDir+\"/122_elan\"\n",
    "\n",
    "# the path to the TEI transcription files\n",
    "pathToTEIDir = shawidataHomeDir+\"/102_derived_tei\"\n",
    "\n",
    "# the path to the NoSkE verticals\n",
    "noSkEVertDir = shawidataHomeDir+\"/131_vert_xml\"\n",
    "\n",
    "# the path to the tei Corpus document produced by this script\n",
    "pathToTeiCorpus = pathToTEIDir+\"/shawiCorpus.xml\"\n",
    "\n",
    "\n",
    "# the path to the audio files\n",
    "pathToRecordingsDir = \"THIS_IS_NOT_USED\"#\"/mnt/univie_orientalistik/SHAWI/Recordings\"\n",
    "\n",
    "proc = PySaxonProcessor(license=False)\n",
    "# SaxonC 1.2.1 Python has many known bugs but isn't maintained anymore\n",
    "# Many of the documented API specs are not working\n",
    "print(proc.version)\n",
    "proc.set_cwd(os.path.dirname(os.path.abspath('')))\n",
    "print(proc.cwd)\n",
    "\n",
    "\n",
    "#set up directories\n",
    "print(\"** setting up directories **\")\n",
    "for i in [dataDir,libDir]: \n",
    "    if os.path.exists(i):\n",
    "        print(\"skipped existing directory '\"+i+\"'\")\n",
    "    else:\n",
    "        os.mkdir(i)\n",
    "        print(\"created directory '\"+i+\"'\")\n",
    "        \n",
    "        \n",
    "# define which steps should be skipped. \n",
    "\n",
    "SKIP_PROCESSING = []#[\"runTEICorpo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfda0dc",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Step 1: get the latest release of the TEI Stylesheets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5960d582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Fetching library TEIC/TEI **\n",
      "We have already the latest version (P5_Release_4.4.0). Exiting\n",
      "\n",
      "** Fetching library TEIC/Stylesheets **\n",
      "We have already the latest version (v7.53.0). Exiting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "# fetch the TEI Stylesheets    \n",
    "def installFromGithub(libraryName):\n",
    "    headers = {\"Accept\" : \"application/vnd.github.v3+json\"}\n",
    "    repo = libraryName\n",
    "    print(\"** Fetching library \"+repo+\" **\")\n",
    "    libBasePath = libDir+\"/\"+repo\n",
    "    \n",
    "    # First we check which tag name the latest release has\n",
    "    r = requests.get(\"https://api.github.com/repos/\"+repo+\"/releases/latest\", headers=headers)\n",
    "    if r.status_code != 200:\n",
    "        print(\"An error occured fetching the latest release. Maybe there isn't any release? \")\n",
    "        print(r.content)\n",
    "        return 1\n",
    "    release = r.json()\n",
    "    tag = release[\"tag_name\"]\n",
    "    \n",
    "    # we check whether we have the latest version already \\\n",
    "    # by checking if the respective path is already installed\n",
    "    libReleasePath = libBasePath+\"/\"+tag\n",
    "    haveLatestVersion = os.path.exists(libReleasePath)\n",
    "    if haveLatestVersion:\n",
    "        print(\"We have already the latest version (\"+tag+\"). Exiting\")\n",
    "        print(\"\")\n",
    "        return libReleasePath\n",
    "    else:\n",
    "        url = release[\"assets\"][0][\"browser_download_url\"]\n",
    "        payload = requests.get(url).content\n",
    "        zipfilename = os.path.basename(url)\n",
    "        os.makedirs(libReleasePath, exist_ok=True)\n",
    "        zipfilePath = libReleasePath +\"/\"+zipfilename\n",
    "        open(zipfilePath, 'wb').write(payload)\n",
    "        ZipFile(zipfilePath).extractall(path=libReleasePath)\n",
    "        print(\"Downloaded latest version (\"+tag+\") to \"+libReleasePath)\n",
    "        print(\"\")\n",
    "        return libReleasePath\n",
    "\n",
    "\n",
    "pathToTEIGuidelines=installFromGithub(\"TEIC/TEI\")\n",
    "pathToTEIStylesheets=installFromGithub(\"TEIC/Stylesheets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c41966",
   "metadata": {},
   "source": [
    "### Step 2: Download the latest version of the Excel Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "842ce3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempting to download file from https://oeawacat.sharepoint.com/sites/ACDH-CH_p_ShawiTypeArabicDialects_Shawi/Shared Documents/General/Shawi_Recordings.xlsx\n",
      "data/Shawi_Recordings.xlsx\n"
     ]
    }
   ],
   "source": [
    "# TODO will need to add credentials if this is run in non-interactive mode\n",
    "def downloadFromSP(sp_filepath, force=False):\n",
    "    url = \"https://\"+sp_baseURL+\"/sites/\"+sp_siteName+\"/\"+sp_filepath\n",
    "    print(\"attempting to download file from \"+url)\n",
    "    filename = os.path.basename(sp_filepath)\n",
    "    downloadPath = dataDir+\"/\"+filename\n",
    "    if os.path.exists(downloadPath) and not force:\n",
    "        print(\"skipping existing file \"+downloadPath)\n",
    "        return downloadPath\n",
    "    else:\n",
    "        s = sharepy.connect(sp_baseURL, username=sp_username, password=sp_pwd)\n",
    "        s.getfile(url, filename=downloadPath)\n",
    "        return downloadPath\n",
    "\n",
    "\n",
    "pathToExcelSheet = downloadFromSP(sp_pathToRecordingsXLSX, force=\"downloadExcelSheet\" not in SKIP_PROCESSING)\n",
    "print(pathToExcelSheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9687813",
   "metadata": {},
   "source": [
    "## Step 2: transform xlsx to TEI table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48c1a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(s, xsl, o, parameters=[]):\n",
    "    # no change in behavior\n",
    "    proc.set_configuration_property(\"xi\", \"on\")\n",
    "    saxon = proc.new_xslt_processor()\n",
    "    saxon.set_source(file_name=os.path.abspath(s))\n",
    "    for i in parameters:\n",
    "        saxon.set_parameter(name=i, value=proc.make_string_value(parameters[i]))\n",
    "    saxon.compile_stylesheet(stylesheet_file=os.path.abspath(xsl))\n",
    "    saxon.set_output_file(os.path.abspath(o))\n",
    "    saxon.transform_to_string()\n",
    "    if saxon.exception_occurred():\n",
    "        # print(getmembers(saxon))\n",
    "        for i in range(saxon.exception_count()-1):\n",
    "            print(saxon.get_error_message(0))\n",
    "        print(os.path.abspath(s)+\" - \"+os.path.abspath(xsl)+\" -> \"+os.path.abspath(o)+\" failed\")\n",
    "    return o # for chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "531fda65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def xlsx2teitable(xlsx, output):\n",
    "\n",
    "    # first, extract contents of XLSX document to a temp directory\n",
    "    unzipPath=xlsx.replace(\".xlsx\",\"\")\n",
    "    os.makedirs(unzipPath, exist_ok=True)\n",
    "    ZipFile(xlsx).extractall(path=unzipPath)\n",
    "    \n",
    "    # then transform the .rels file using the TEIC Stylesheets \n",
    "    pathToXlsxtoteiXSL=pathToTEIStylesheets+\"/xml/tei/stylesheet/xlsx/xlsxtotei.xsl\"\n",
    "\n",
    "    params = {\n",
    "        \"inputDir\" : pathlib.Path(os.path.abspath(unzipPath)).as_uri(),\n",
    "        \"workDir\" : pathlib.Path(os.path.abspath(unzipPath)).as_uri()\n",
    "        \n",
    "    }\n",
    "\n",
    "    transform(\n",
    "        s = unzipPath+\"/_rels/.rels\", \n",
    "        xsl = pathToXlsxtoteiXSL, \n",
    "        o = output, \n",
    "        parameters=params\n",
    "    )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e041e152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Shawi_Recordings.xml\n"
     ]
    }
   ],
   "source": [
    "pathToTEItable=pathToExcelSheet.replace(\".xlsx\",\".xml\")\n",
    "\n",
    "if not \"xlsx2teitable\" in SKIP_PROCESSING:    \n",
    "    xlsx2teitable(xlsx=pathToExcelSheet, output=pathToTEItable)\n",
    "    debugstring=\"\"\"<!-- \n",
    "   THIS FILE IS INCLUDED IN THE GIT REPOSITORY ONLY FOR DEBUGGING PURPOSES. \n",
    "   \n",
    "   The source of this file is constantly being edited at \n",
    "   https://oeawacat.sharepoint.com/sites/ACDH-CH_p_ShawiTypeArabicDialects_Shawi/_layouts/15/Doc.aspx?sourcedoc={F01FF43B-2409-4E31-A5BF-653E0559B160}&file=SHAWI%20Recordings.xlsx&action=default&mobileredirect=true&cid=f7311564-c2b6-4b08-9a52-468547688408\n",
    "   So this copy is most probably already outdated.\n",
    "   \n",
    "  To update it, you can either run https://gitlab.com/acdh-oeaw/shawibarab/shawi-data/-/blob/main/080_scripts_generic/080_01_ELAN2TEI/ELAN2TEI.ipyn\n",
    "   *OR*  \n",
    "   1) download the Excel file manually from Sharepoint\n",
    "   2) and tranform it to TEI using oxgarage.tei-c.org/ \n",
    "   \n",
    "-->\n",
    "    \"\"\"\n",
    "    f = open(pathToTEItable,mode=\"r\",encoding=\"UTF8\")\n",
    "    src = f.read()\n",
    "    new = src.replace('<?xml version=\"1.0\" encoding=\"UTF-8\"?>','<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'+debugstring)\n",
    "    f.close()\n",
    "    f = open(pathToTEItable, mode=\"wt\",encoding=\"UTF8\")\n",
    "    f.write(new)\n",
    "    f.close()\n",
    "        \n",
    "    print(pathToTEItable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca2fcd",
   "metadata": {},
   "source": [
    "## transform TEI table to corpus header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0889b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../102_derived_tei/shawiCorpus.xml\n"
     ]
    }
   ],
   "source": [
    "pathToTeitableToCorpusXSL=pathToShawiStylesheetsDir+\"/table2corpus.xsl\"\n",
    "params = {\n",
    "    \"pathToRecordings\" : pathlib.Path(os.path.abspath(pathToRecordingsDir)).as_uri()\n",
    "}\n",
    "try:\n",
    "    transform(pathToTEItable, pathToTeitableToCorpusXSL, pathToTeiCorpus, params)\n",
    "except:\n",
    "    print(\"an error occured\")\n",
    "print(pathToTeiCorpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbd00c7",
   "metadata": {},
   "source": [
    "## Run TEICorpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8914cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping download\n",
      "skipping download\n",
      "lib/*\n"
     ]
    }
   ],
   "source": [
    "def installFromUrl(url, force=False):\n",
    "    r = requests.get(url)\n",
    "    filename = os.path.basename(urlsplit(url).path)\n",
    "    downloadpath = libDir+\"/\"+filename\n",
    "    if os.path.exists(downloadpath) and not force:\n",
    "        print(\"skipping download\")\n",
    "    else:\n",
    "        open(downloadpath, 'wb').write(r.content)\n",
    "        print(\"file \"+downloadpath+\" downloaded\")\n",
    "    return downloadpath\n",
    "\n",
    "# TODO check for filetype and automatically extract zip file \n",
    "# so this can be re-used for the insta\n",
    " \n",
    "installFromUrl(\"https://github.com/christopheparisse/teicorpo/blob/e06a01ad5cb4c3aef631b3749ce59b5eb6f5ea11/teicorpo.jar?raw=true\")\n",
    "installFromUrl(\"https://repo1.maven.org/maven2/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar\")\n",
    "pathToTeiCorpo=libDir+\"/*\"\n",
    "print(pathToTeiCorpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68193a14",
   "metadata": {},
   "source": [
    "Collect all ELAN documents from pathToELANDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fc55161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/simar/shawi-data/122_elan/Urfa-012_Lentils-Harran-2010.eaf\n",
      "/home/simar/shawi-data/122_elan/Urfa-077_Jinn-Harran-2010.eaf\n"
     ]
    }
   ],
   "source": [
    "ELANDocs = []\n",
    "\n",
    "for i in os.scandir(pathToELANDir):\n",
    "    if os.path.basename(i).endswith(\".eaf\"):\n",
    "        ELANDocs.append({\n",
    "            \"filepath\" : os.path.abspath(i),\n",
    "            \"filename\" : os.path.basename(i),\n",
    "            \"basename\" : Path(i).stem\n",
    "        })\n",
    "for d in ELANDocs:\n",
    "    print(d[\"filepath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec70e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTEICorpo(docs = dict):\n",
    "    for i in docs:\n",
    "        pathToInput = i[\"filepath\"]\n",
    "        filenameELAN = i[\"filename\"]\n",
    "        runtime = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "        tmpDir = pathToTEIDir+\"/\"+runtime\n",
    "        filenameTEI = i[\"basename\"]+\".xml\"\n",
    "        pathToOutput = tmpDir+\"/\"+\"ELAN_\"+filenameTEI\n",
    "        os.makedirs(tmpDir, exist_ok=True)\n",
    "        i[\"filepath_tmp_TEI\"] = os.path.abspath(pathToOutput)\n",
    "        i[\"tmpDir\"] = tmpDir\n",
    "        output = os.path.abspath(pathToTEIDir + \"/\" + i[\"basename\"] + \".xml\")\n",
    "        i[\"TEI\"] = os.path.abspath(output)\n",
    "        res = subprocess.run([\"java\", \"-cp\", pathToTeiCorpo, \"-Dfile.encoding=UTF-8\", \"fr.ortolang.teicorpo.TeiCorpo\", \"-from\",\"elan\", \"-to\",\"tei\", \"-o\",pathToOutput, pathToInput], capture_output=True, encoding=\"UTF-8\")\n",
    "        print(res.stdout)\n",
    "        print(res.stderr)\n",
    "        print(pathToOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38413b21",
   "metadata": {},
   "source": [
    "run TEI Corpo on all ELANDocs, writing the path to the TEI output back to the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2862351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../102_derived_tei/2022-07-22_21-22/ELAN_Urfa-012_Lentils-Harran-2010.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../102_derived_tei/2022-07-22_21-22/ELAN_Urfa-077_Jinn-Harran-2010.xml\n"
     ]
    }
   ],
   "source": [
    "if not \"runTEICorpo\" in SKIP_PROCESSING:\n",
    "    runTEICorpo(docs=ELANDocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51dc1f",
   "metadata": {},
   "source": [
    "### Prepare\n",
    "\n",
    "Merge metadata and TEICorpo output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a40c251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mergeMetadata(docInfo, p):\n",
    "    return transform(\n",
    "        s = docInfo[\"filepath_tmp_TEI\"],\n",
    "        xsl = pathToShawiStylesheetsDir+\"/mergeHeaderAndTranscription.xsl\",\n",
    "        o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_00_metaMerged.xml\",\n",
    "        parameters = p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71570084",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenize\n",
    "\n",
    "Run a local copy of [xsl-tokenizer](https://github.com/acdh-oeaw/xsl-tokenizer)\n",
    "\n",
    "### Step 0 (optional)\n",
    "\n",
    "Regenerate the XSLs used in the following steps.\n",
    "This can not be done with saxonpy (xincludes are not resolved)\n",
    "use\n",
    "```bash\n",
    "java -jar Saxon-HE-9.9.1-8.jar -s:profile.xml -xi:on -xsl:xsl/make_xsl.xsl\n",
    "```\n",
    "\n",
    "For all the ELAN files converted to TEI:\n",
    "\n",
    "### Step 1\n",
    "\n",
    "Remove new lines and store to intermediate document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "feb48707-d990-4737-8115-277497add47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNL(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_00_metaMerged.xml\", \n",
    "        xsl = \"./tokenizer/xsl/rmNl.xsl\", \n",
    "        o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_01_nlRmd.xml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef95efdd-eaaa-4132-a42b-e70f6a0225b5",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Tokenize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a825ea8-f03d-4f56-b4ef-158817e5cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_01_nlRmd.xml\", \n",
    "        xsl = \"./tokenizer/wrapper_toks.xsl\", \n",
    "        o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_02_toks.xml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33998805-c4f2-4039-999b-419acb3e69f9",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Add Part-Attributes and explicit token links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3946396-3a73-4180-873f-2361a669cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addP(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_02_toks.xml\", \n",
    "        xsl = \"./tokenizer/wrapper_addP.xsl\", \n",
    "        o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_03_tokenized.xml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729253b-f6e2-42b8-b4ef-e67319aed15b",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "Do some post tokenization processing specific to the Shawi project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6292bd18-6718-4d64-97c7-c4c093283f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postProcess(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_03_tokenized.xml\", \n",
    "        xsl = \"./tokenizer/postTokenization/1.xsl\", \n",
    "        o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_04_posttok.xml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44acba-435d-449c-afc1-1288233036e1",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "\n",
    "Create a intermedieate vertical document that has a structure suited for further processing to TEI and to NoSkE verticals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2e07285-908a-4f6e-89ff-43b4f59e103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVertSource(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_04_posttok.xml\", \n",
    "        xsl = \"./tokenizer/wrapper_xtoks2vert.xsl\", \n",
    "        o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_05_vert.xml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305fb51-e68b-43b3-a818-08dbf7aa7d46",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "\n",
    "Create the final tokenized TEI document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "22000a92-d0d5-465e-876e-38865682d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFinalTEI(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_05_vert.xml\",\n",
    "        xsl = \"./tokenizer/xsl/xtoks2tei.xsl\", \n",
    "        o = docInfo[\"TEI\"],\n",
    "        parameters = {\n",
    "            \"preserve-ws\": \"false\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107ed8f-dfa4-41b8-9f24-c63a9c71589c",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "\n",
    "Create a vertical vor NoSkE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed763150-c07c-45d0-b077-05f8839e3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNoSkEVert(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_05_vert.xml\",\n",
    "        xsl = \"./tokenizer/wrapper_vert2txt.xsl\", \n",
    "        o = noSkEVertDir + \"/\" + docInfo[\"basename\"] + \".xml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f24c432-2ac1-48d8-a50f-604b34b808d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/simar/shawi-data/102_derived_tei/shawiCorpus.xml\n",
      "Urfa-012_Lentils-Harran-2010: /home/simar/shawi-data/102_derived_tei/2022-07-22_21-22/ELAN_Urfa-012_Lentils-Harran-2010.xml -> /home/simar/shawi-data/102_derived_tei/Urfa-077_Jinn-Harran-2010.xml\n",
      "Urfa-012_Lentils-Harran-2010: done.\n",
      "Urfa-077_Jinn-Harran-2010: /home/simar/shawi-data/102_derived_tei/2022-07-22_21-22/ELAN_Urfa-077_Jinn-Harran-2010.xml -> /home/simar/shawi-data/102_derived_tei/Urfa-077_Jinn-Harran-2010.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "addP.xsl\n",
      "xtoks2vert.xsl\n",
      "Debug level: false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urfa-077_Jinn-Harran-2010: done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "addP.xsl\n",
      "xtoks2vert.xsl\n",
      "Debug level: false\n"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath(pathToTeiCorpus))\n",
    "mergeParam = { \"pathToCorpusDoc\": pathlib.Path(os.path.abspath(pathToTeiCorpus)).as_uri() }\n",
    "for doc in ELANDocs:\n",
    "    print(doc[\"basename\"]+': '+doc[\"filepath_tmp_TEI\"]+\" -> \"+doc[\"TEI\"])\n",
    "    mergeMetadata(doc, mergeParam)\n",
    "    removeNL(doc)\n",
    "    tokenize(doc)\n",
    "    addP(doc)\n",
    "    postProcess(doc)\n",
    "    createVertSource(doc)\n",
    "    createFinalTEI(doc)\n",
    "    createNoSkEVert(doc)\n",
    "    print(doc[\"basename\"]+\": done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fb522d",
   "metadata": {},
   "source": [
    "## Replace TEI elements with x-includes in corpus document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1045b01-72db-4104-8ebe-e4c4dffa385d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('080_01_ELAN2TEI-YDe5vPj0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b0b902fac6ad7dd00456e1f7dc72379c0baf1ab5135d56a56b79f9771306c5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
